# -*- coding: utf-8 -*-
"""경주2풍력 발전량 예측.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QXeQj9rHwkNohsN4zaYYGQRAA8RhTVQM

# SCADA_wind turbine 발전량 합계_전처리
"""

import pandas as pd
import zipfile
import os
from google.colab import drive

# ==============================
# 1. 구글 드라이브 마운트
# ==============================
drive.mount('/content/drive')

# ==============================
# 2. 압축 해제
# ==============================
zip_path = '/content/drive/MyDrive/풍력발전_실전데이터/scada.zip'
extract_root = '/content/scada'
os.makedirs(extract_root, exist_ok=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_root)

# ==============================
# 3. 실제 압축 풀린 폴더 확인
# ==============================
print("압축 해제된 폴더 구조:")
for root, dirs, files in os.walk(extract_root):
    level = root.replace(extract_root, "").count(os.sep)
    indent = " " * 4 * level
    print(f"{indent}{os.path.basename(root)}/")
    subindent = " " * 4 * (level + 1)
    for f in files:
        print(f"{subindent}{f}")

# ==============================
# 4. 사용할 파일 목록 (2020~2023)
# ==============================
files_to_use = [
    'scada_gyeongju_2020_10min.xlsx',
    'scada_gyeongju_2021_10min.xlsx',
    'scada_gyeongju_2022_10min.xlsx',
    'scada_gyeongju_2023_10min.xlsx'
]

# ==============================
# 5. 실제 데이터 경로 탐색 함수
# ==============================
def find_file(root, filename):
    for dirpath, _, filenames in os.walk(root):
        if filename in filenames:
            return os.path.join(dirpath, filename)
    return None

# ==============================
# 6. 발전량 데이터 전처리
# ==============================
energy_col_raw = 'Energy Production\nActive Energy Production\n[KWh]'
energy_col_clean = 'wind_farm_energy_kwh'
df_all = []

for file_name in files_to_use:
    file_path = find_file(extract_root, file_name)  # 자동 경로 탐색
    if file_path is None:
        print(f" 파일 없음: {file_name}")
        continue
    try:
        xls = pd.ExcelFile(file_path)
        for sheet in xls.sheet_names:
            try:
                # 필요한 컬럼만 추출
                df = xls.parse(sheet_name=sheet, usecols=['Date/Time', energy_col_raw], header=5)
                df.rename(columns={energy_col_raw: energy_col_clean}, inplace=True)

                # Summation 행 제거
                mask = ~df['Date/Time'].astype(str).str.contains('Summation', case=False, na=False)
                df = df.loc[mask].copy()

                # 날짜 변환
                df['Date/Time'] = pd.to_datetime(df['Date/Time'], errors='coerce')
                df = df.dropna(subset=['Date/Time', energy_col_clean])

                df_all.append(df)
            except Exception as e:
                print(f" 시트 오류: {file_name} - {sheet}: {e}")
    except Exception as e:
        print(f" 파일 열기 오류: {file_name}: {e}")

# ==============================
# 7. 전체 데이터 합산 (시간별 발전량)
# ==============================
if len(df_all) == 0:
    raise ValueError(" 불러온 데이터가 없습니다. 파일 경로를 확인하세요.")

df_total = pd.concat(df_all)
df_farm = df_total.groupby('Date/Time')[energy_col_clean].sum().reset_index()
df_farm.columns = ['timestamp', 'wind_farm_energy_kwh']
df_farm.set_index('timestamp', inplace=True)
df_farm = df_farm.sort_index()

# ==============================
# 8. 연속된 0이 6개 이상 → NaN 처리
# ==============================
zero_mask = (df_farm['wind_farm_energy_kwh'] == 0).astype(int)
zero_groups = (zero_mask.diff(1) != 0).cumsum()
zero_counts = zero_mask.groupby(zero_groups).transform('sum')
df_farm.loc[(zero_mask == 1) & (zero_counts >= 6), 'wind_farm_energy_kwh'] = pd.NA

# ==============================
# 9. 결측치 처리 (보간 + ffill + bfill + 최종 0 대체)
# ==============================
df_farm['wind_farm_energy_kwh'] = (
    df_farm['wind_farm_energy_kwh']
    .interpolate(method='linear')  # 선형 보간
    .fillna(method='ffill')        # 앞 값으로 채움
    .fillna(method='bfill')        # 뒤 값으로 채움
    .fillna(0)                     # 남은 NaN은 0으로 대체
)

# ==============================
# 10. 1시간 단위 리샘플링 (합계 기준)
# ==============================
df_farm_hourly = df_farm.resample('1H').sum(min_count=1)

# ==============================
# 11. 저장
# ==============================
save_path = '/content/drive/MyDrive/풍력발전_실전데이터/wind_farm_energy_preprocessed_hourly.csv'
df_farm_hourly.reset_index().to_csv(save_path, index=False)

# ==============================
# 12. 확인
# ==============================
print("전처리 완료 (2020~2023, 1시간 단위).")
print("데이터 기간:", df_farm_hourly.index.min(), "~", df_farm_hourly.index.max())
print("NaN 개수:", df_farm_hourly.isna().sum().sum())
print(df_farm_hourly.head(10))
print(df_farm_hourly.tail(10))

"""# 센서 데이터 전처리 및 Nacelle Wind Direction [deg] 변환"""

import pandas as pd
import numpy as np
import zipfile
import os
from sklearn.preprocessing import MinMaxScaler
from google.colab import drive

# ==============================
# 1. 구글 드라이브 마운트
# ==============================
drive.mount('/content/drive')

# ==============================
# 2. 압축 해제
# ==============================
zip_path = '/content/drive/MyDrive/풍력발전_실전데이터/scada.zip'
extract_root = '/content/scada_extracted'
extract_path = os.path.join(extract_root, 'scada')
os.makedirs(extract_root, exist_ok=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_root)

# ==============================
# 3. 사용할 파일 목록 (2020~2023)
# ==============================
files_to_use = [
    'scada_gyeongju_2020_10min.xlsx',
    'scada_gyeongju_2021_10min.xlsx',
    'scada_gyeongju_2022_10min.xlsx',
    'scada_gyeongju_2023_10min.xlsx'
]

# ==============================
# 4. 사용할 센서 컬럼
# ==============================
use_cols = [
    'Date/Time',
    'Nacelle\nWind Speed\n[m/s]',
    'Nacelle\nWind Direction\n[deg]',
    'Rotor\nRotor Speed\n[rpm]',
    'Nacelle\nAir Density\n[kg/㎥]'
]

df_all = []

# ==============================
# 5. 각 파일/시트에서 필요한 컬럼 추출
# ==============================
for file_name in files_to_use:
    file_path = os.path.join(extract_path, file_name)
    try:
        xls = pd.ExcelFile(file_path)
        for sheet in xls.sheet_names:
            try:
                df = xls.parse(sheet_name=sheet, usecols=use_cols, header=5)

                # 날짜 처리
                df = df.dropna(subset=['Date/Time'])
                df['Date/Time'] = pd.to_datetime(df['Date/Time'], errors='coerce')
                df = df.dropna(subset=['Date/Time'])

                df_all.append(df)
            except Exception as e:
                print(f"시트 오류: {file_name} - {sheet}: {e}")
    except Exception as e:
        print(f"파일 열기 오류: {file_name}: {e}")

# ==============================
# 6. 통합 및 시간 기준 정렬
# ==============================
df_total = pd.concat(df_all)
df_total = df_total.sort_values(by='Date/Time').reset_index(drop=True)
df_total = df_total.set_index('Date/Time')

# ==============================
# 7. 연속된 0이 6개 이상인 구간을 NaN 처리
# ==============================
for col in df_total.columns:
    zero_mask = (df_total[col] == 0).astype(int)
    zero_groups = (zero_mask.diff(1) != 0).cumsum()
    zero_counts = zero_mask.groupby(zero_groups).transform('sum')
    df_total.loc[(zero_mask == 1) & (zero_counts >= 6), col] = pd.NA

# ==============================
# 8. 결측치 보간 (선형 보간 + 앞뒤 보강)
# ==============================
df_total = (
    df_total.interpolate(method='linear')
    .fillna(method='ffill')
    .fillna(method='bfill')
)

# ==============================
# 9. 풍향을 사인/코사인으로 변환
# ==============================
wind_dir_col = 'Nacelle\nWind Direction\n[deg]'
df_total['wind_dir_rad'] = np.deg2rad(df_total[wind_dir_col])
df_total['wind_dir_sin'] = np.sin(df_total['wind_dir_rad'])
df_total['wind_dir_cos'] = np.cos(df_total['wind_dir_rad'])
df_total.drop(columns=['wind_dir_rad', wind_dir_col], inplace=True)

# ==============================
# 10. 1시간 단위로 리샘플링 (평균값)
# ==============================
df_hourly = df_total.resample('1H').mean()

# ==============================
# 11. 정규화 (MinMax 기준)
# ==============================
scaler_hourly = MinMaxScaler()
df_hourly[df_hourly.columns] = scaler_hourly.fit_transform(df_hourly[df_hourly.columns])

# ==============================
# 12. NaN 최종 처리 (남아있는 NaN → 0 대체)
# ==============================
print("보간/대체 전 NaN 개수:\n", df_hourly.isna().sum())
print("총 NaN 개수:", df_hourly.isna().sum().sum())

df_hourly = df_hourly.fillna(0)

print("\n보간/대체 후 NaN 개수:\n", df_hourly.isna().sum())
print("총 NaN 개수:", df_hourly.isna().sum().sum())

# ==============================
# 13. 저장
# ==============================
save_path = '/content/drive/MyDrive/풍력발전_실전데이터/scada_sensor_preprocessed_hourly.csv'
df_hourly.reset_index().to_csv(save_path, index=False)

# ==============================
# 14. 확인
# ==============================
print("\n 전처리 완료 (2020~2023, 센서 데이터 1시간 단위).")
print("데이터 기간:", df_hourly.index.min(), "~", df_hourly.index.max())
print(df_hourly.head())
print(df_hourly.tail())

"""# LSTM model 학습을 위해 2개 파일 병합"""

import pandas as pd
from google.colab import drive

# ==============================
# 1. 구글 드라이브 마운트
# ==============================
drive.mount('/content/drive')

# ==============================
# 2. 파일 경로 지정 (앞에서 만든 전처리 파일 경로 반영)
# ==============================
sensor_path = "/content/drive/MyDrive/풍력발전_실전데이터/scada_sensor_preprocessed_hourly.csv"
energy_path = "/content/drive/MyDrive/풍력발전_실전데이터/wind_farm_energy_preprocessed_hourly.csv"

# ==============================
# 3. 데이터 불러오기
# ==============================
df_sensor = pd.read_csv(sensor_path, parse_dates=['Date/Time'])
df_energy = pd.read_csv(energy_path, parse_dates=['timestamp'])

# ==============================
# 4. 컬럼 이름 정리 (센서 시간 컬럼 이름을 발전량과 통일)
# ==============================
df_sensor.rename(columns={'Date/Time': 'timestamp'}, inplace=True)

# ==============================
# 5. 병합 (timestamp 기준, inner join → 공통 구간만 사용)
# ==============================
df_merged = pd.merge(df_sensor, df_energy, on='timestamp', how='inner')

# ==============================
# 6. 시간순 정렬
# ==============================
df_merged = df_merged.sort_values(by='timestamp').reset_index(drop=True)

# ==============================
# 7. NaN 처리 (센서/발전량 모두)
# ==============================
df_merged = (
    df_merged
    .interpolate(method='linear')  # 선형 보간
    .fillna(method='ffill')        # 앞 값으로 채움
    .fillna(method='bfill')        # 뒤 값으로 채움
    .fillna(0)                     # 최종적으로 0 대체
)

# ==============================
# 8. 저장
# ==============================
save_path = "/content/drive/MyDrive/풍력발전_실전데이터/scada_merged_for_lstm.csv"
df_merged.to_csv(save_path, index=False)

# ==============================
# 9. 확인
# ==============================
print("병합 완료")
print("저장 경로:", save_path)
print("데이터 기간:", df_merged['timestamp'].min(), "~", df_merged['timestamp'].max())
print("NaN 개수:", df_merged.isna().sum().sum())
print(df_merged.head())
print(df_merged.tail())

"""# 병합한 데이터를 통해 만든 LSTM model"""

# ==============================
# 0. 라이브러리 & 시드 고정
# ==============================
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import joblib

# 재현성을 위한 시드 고정
np.random.seed(42)
tf.random.set_seed(42)

# ==============================
# 1. 데이터 불러오기
# ==============================
data_path = "/content/drive/MyDrive/풍력발전_실전데이터/scada_merged_for_lstm.csv"
df = pd.read_csv(data_path, parse_dates=['timestamp'])
df = df.set_index('timestamp')

print("데이터 기간:", df.index.min(), "~", df.index.max())
print("컬럼:", df.columns.tolist())
print(df.head())

# ==============================
# 2. 입력(X), 출력(y) 분리
# ==============================
feature_cols = [c for c in df.columns if c != "wind_farm_energy_kwh"]  # 센서 데이터
target_col = "wind_farm_energy_kwh"  # 발전량

X = df[feature_cols].values

# ==============================
# 2-1. 타깃 결측치 처리 (중요)
# ==============================
df[target_col] = (
    df[target_col]
    .interpolate(method='linear')   # 선형 보간
    .ffill()                        # 앞 값으로 채움
    .bfill()                        # 뒤 값으로 채움
    .fillna(0)                      # 최종적으로 0 대체
)

y = df[target_col].values.reshape(-1, 1)

print("결측치 처리 후 타깃 결측 개수:", df[target_col].isna().sum())

# ==============================
# 3. 정규화 (스케일러 저장 포함)
# ==============================
scaler_X = MinMaxScaler()
scaler_y = MinMaxScaler()

X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y)

# 스케일러 저장 (추가)
joblib.dump(scaler_X, "/content/drive/MyDrive/풍력발전_실전데이터/scaler_X.pkl")
joblib.dump(scaler_y, "/content/drive/MyDrive/풍력발전_실전데이터/scaler_y.pkl")

print("X_scaled 범위:", X_scaled.min(), "~", X_scaled.max())
print("y_scaled 범위:", y_scaled.min(), "~", y_scaled.max())

# ==============================
# 4. 시계열 데이터셋 생성
# ==============================
def create_sequences(X, y, lookback=24, horizon=1):
    Xs, ys = [], []
    for i in range(len(X) - lookback - horizon + 1):
        Xs.append(X[i : i + lookback])
        ys.append(y[i + lookback + horizon - 1])
    return np.array(Xs), np.array(ys)

lookback = 24   # 지난 24시간 입력
horizon = 1     # 다음 1시간 예측

X_seq, y_seq = create_sequences(X_scaled, y_scaled, lookback, horizon)

print("X_seq shape:", X_seq.shape)  # (샘플 수, 24, 특성 수)
print("y_seq shape:", y_seq.shape)  # (샘플 수, 1)

# ==============================
# 5. 학습/검증/테스트 분할
# ==============================
X_train, X_temp, y_train, y_temp = train_test_split(
    X_seq, y_seq, test_size=0.2, shuffle=False
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, shuffle=False
)

print("학습 데이터:", X_train.shape, y_train.shape)
print("검증 데이터:", X_val.shape, y_val.shape)
print("테스트 데이터:", X_test.shape, y_test.shape)

# ==============================
# 6. LSTM 모델 정의
# ==============================
model = Sequential([
    LSTM(64, return_sequences=True, input_shape=(lookback, X_seq.shape[2])),
    Dropout(0.2),
    LSTM(32),
    Dropout(0.2),
    Dense(1)  # 출력: 발전량
])

model.compile(optimizer='adam', loss='mse', metrics=['mae'])
model.summary()

# ==============================
# 7. 모델 학습
# ==============================
es = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)

history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=50,
    batch_size=32,
    callbacks=[es],
    verbose=1
)

# ==============================
# 8. 평가
# ==============================
loss, mae = model.evaluate(X_test, y_test)
print("테스트 MSE:", loss)
print("테스트 MAE:", mae)

# 역정규화된 RMSE 계산
y_pred = model.predict(X_test)
y_pred_inv = scaler_y.inverse_transform(y_pred)
y_test_inv = scaler_y.inverse_transform(y_test)

rmse = np.sqrt(np.mean((y_pred_inv - y_test_inv) ** 2))
print("테스트 RMSE (실제 단위):", rmse)

# ==============================
# 9. 모델 저장 (최신 포맷 권장)
# ==============================
save_model_path = "/content/drive/MyDrive/풍력발전_실전데이터/lstm_final_model.keras"
model.save(save_model_path)
print("모델 저장 완료:", save_model_path)

"""# 2020~2023 환경 데이터 -> 2024년 환경 데이터 예측"""

# ==============================
# 0. 라이브러리 & 시드 고정
# ==============================
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from google.colab import drive

# 구글 드라이브 마운트
drive.mount('/content/drive')

# 시드 고정
np.random.seed(42)
tf.random.set_seed(42)

# ==============================
# 1. 데이터 불러오기
# ==============================
data_path = "/content/drive/MyDrive/풍력발전_실전데이터/scada_merged_for_lstm.csv"
df = pd.read_csv(data_path, parse_dates=['timestamp'])
df = df.set_index('timestamp')

# target(발전량) 제거 → 환경데이터만 사용
env_cols = [c for c in df.columns if c != "wind_farm_energy_kwh"]
df_env = df[env_cols]

print("환경 데이터 기간:", df_env.index.min(), "~", df_env.index.max())
print("환경 변수:", env_cols)

# ==============================
# 2. 정규화
# ==============================
scaler_env = MinMaxScaler()
env_scaled = scaler_env.fit_transform(df_env)

print("정규화 후 범위:", env_scaled.min(), "~", env_scaled.max())

# ==============================
# 3. 시계열 데이터셋 생성
# ==============================
def create_sequences(X, lookback=72, horizon=1):
    Xs, ys = [], []
    for i in range(len(X) - lookback - horizon + 1):
        Xs.append(X[i : i + lookback])
        ys.append(X[i + lookback + horizon - 1])  # 다변량 y
    return np.array(Xs), np.array(ys)

lookback = 72   # 지난 72시간 입력
horizon = 1     # 다음 1시간 예측

X_seq, y_seq = create_sequences(env_scaled, lookback, horizon)

print("X_seq shape:", X_seq.shape)  # (샘플 수, 72, 변수 개수)
print("y_seq shape:", y_seq.shape)  # (샘플 수, 변수 개수)

# ==============================
# 4. 학습/검증/테스트 분할
# ==============================
X_train, X_temp, y_train, y_temp = train_test_split(
    X_seq, y_seq, test_size=0.2, shuffle=False
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, shuffle=False
)

print("학습 데이터:", X_train.shape, y_train.shape)
print("검증 데이터:", X_val.shape, y_val.shape)
print("테스트 데이터:", X_test.shape, y_test.shape)

# ==============================
# 5. LSTM 모델 정의
# ==============================
model_env = Sequential([
    LSTM(128, return_sequences=True, input_shape=(lookback, X_seq.shape[2])),
    Dropout(0.2),
    LSTM(64),
    Dropout(0.2),
    Dense(X_seq.shape[2])  # 출력 차원 = 환경변수 개수
])

model_env.compile(optimizer='adam', loss='mse', metrics=['mae'])
model_env.summary()

# ==============================
# 6. 모델 학습
# ==============================
es = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)

history = model_env.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=50,
    batch_size=32,
    callbacks=[es],
    verbose=1
)

# ==============================
# 7. 평가
# ==============================
loss, mae = model_env.evaluate(X_test, y_test)
print("환경데이터 예측 모델 - 테스트 MSE:", loss)
print("환경데이터 예측 모델 - 테스트 MAE:", mae)

# ==============================
# 8. 2024년 환경데이터 예측
# ==============================
# 마지막 72시간 데이터를 seed로 해서 → 2024년 전체 예측 반복
future_steps = 24 * 365  # 8760시간
last_window = env_scaled[-lookback:]  # 마지막 72시간

future_preds = []

for _ in range(future_steps):
    x_input = last_window.reshape(1, lookback, X_seq.shape[2])
    y_pred = model_env.predict(x_input, verbose=0)
    future_preds.append(y_pred[0])
    # 슬라이딩 윈도우 업데이트
    last_window = np.vstack([last_window[1:], y_pred[0]])

# ==============================
# 9. 역정규화 & 저장 (방법2 적용)
# ==============================
future_preds = np.array(future_preds)
future_preds_inv = scaler_env.inverse_transform(future_preds)

future_index = pd.date_range(start="2024-01-01 00:00:00", periods=future_steps, freq="H")
df_future = pd.DataFrame(future_preds_inv, index=future_index, columns=env_cols)

save_path_future = "/content/drive/MyDrive/풍력발전_실전데이터/env_predicted_2024.csv"
df_future.reset_index().rename(columns={'index': 'timestamp'}).to_csv(save_path_future, index=False)

print("2024년 환경데이터 예측 완료, 저장 경로:", save_path_future)
print(df_future.head())
print(df_future.tail())

"""# 2024년 환경 예측 데이터를 활용하여 2024년 발전량 예측 (model 기존 모델을 이용)"""

# ==============================
# 0. 라이브러리
# ==============================
import pandas as pd
import numpy as np
import joblib
from tensorflow.keras.models import load_model
from google.colab import drive

# 구글 드라이브 마운트
drive.mount('/content/drive')

# ==============================
# 1. 스케일러 불러오기 (pkl 사용)
# ==============================
scaler_X = joblib.load("/content/drive/MyDrive/풍력발전_실전데이터/scaler_X.pkl")
scaler_y = joblib.load("/content/drive/MyDrive/풍력발전_실전데이터/scaler_y.pkl")
print("스케일러 불러오기 완료")

# ==============================
# 2. 저장된 발전량 예측 LSTM 모델 불러오기
# ==============================
model_path = "/content/drive/MyDrive/풍력발전_실전데이터/lstm_final_model.keras"
model_power = load_model(model_path)
print("발전량 예측 모델 불러오기 완료")

# ==============================
# 3. 2024년 환경 데이터 불러오기
# ==============================
env_path = "/content/drive/MyDrive/풍력발전_실전데이터/env_predicted_2024.csv"
df_env_2024 = pd.read_csv(env_path, parse_dates=['timestamp'])
df_env_2024 = df_env_2024.set_index('timestamp')

# 동일 스케일러로 변환
X_2024_scaled = scaler_X.transform(df_env_2024.values)

# ==============================
# 4. 시퀀스 생성 (lookback=24)
# ==============================
def create_sequences(X, lookback=24):
    Xs = []
    for i in range(len(X) - lookback):
        Xs.append(X[i : i + lookback])
    return np.array(Xs)

lookback = 24
X_2024_seq = create_sequences(X_2024_scaled, lookback)

print("2024년 환경데이터 입력 shape:", X_2024_seq.shape)

# ==============================
# 5. 발전량 예측 & 역정규화
# ==============================
y_2024_scaled = model_power.predict(X_2024_seq, verbose=1)
y_2024 = scaler_y.inverse_transform(y_2024_scaled)

# ==============================
# 6. 결과 저장 (시간별 발전량)
# ==============================
future_index = pd.date_range(
    start="2024-01-01 00:00:00",
    periods=len(y_2024),
    freq="h"   # 'H' 대신 'h' 사용 (FutureWarning 방지)
)
df_power_2024 = pd.DataFrame(y_2024, index=future_index, columns=['predicted_wind_farm_energy_kwh'])

save_path = "/content/drive/MyDrive/풍력발전_실전데이터/power_predicted_2024.csv"
df_power_2024.to_csv(save_path)

print("2024년 발전량 예측 완료, 저장 경로:", save_path)
print(df_power_2024.head())
print(df_power_2024.tail())

# ==============================
# 7. 결과 분석 (추가)
# ==============================
# ① 시간당 발전량 (원본 출력 그대로)
print("\n===== 2024년 시간당 예측 발전량 (앞부분) =====")
print(df_power_2024.head())

print("\n===== 2024년 시간당 예측 발전량 (뒷부분) =====")
print(df_power_2024.tail())

# ② 2024년 총 발전량 (kWh 합계)
total_energy_2024 = df_power_2024['predicted_wind_farm_energy_kwh'].sum()
print("\n===== 2024년 총 예측 발전량 =====")
print(f"{total_energy_2024:,.2f} kWh")